{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0145ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, LabelEncoder, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bbf298b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Dataset Shape: (20, 9)\n",
      "\n",
      "Custom Dataset - First 5 rows:\n",
      "   customer_id   age   income education_level  purchase_amount     category  \\\n",
      "0            1  25.0  45000.0        Bachelor           156.75  Electronics   \n",
      "1            2   NaN  52000.0          Master            89.50     Clothing   \n",
      "2            3  45.0  78000.0             PhD           234.60        Books   \n",
      "3            4  29.0      NaN        Bachelor            67.80  Electronics   \n",
      "4            5  35.0  61000.0             NaN           123.45     Clothing   \n",
      "\n",
      "   satisfaction_rating  gender  total_purchases  \n",
      "0                  4.2    Male               12  \n",
      "1                  3.8  Female                8  \n",
      "2                  4.5    Male               25  \n",
      "3                  NaN  Female                5  \n",
      "4                  3.2    Male               15  \n",
      "\n",
      "Tips Dataset Shape: (244, 7)\n",
      "Flights Dataset Shape: (144, 3)\n",
      "Titanic Dataset Shape: (891, 15)\n"
     ]
    }
   ],
   "source": [
    "df_custom = pd.read_csv('data.csv')\n",
    "print(\"Custom Dataset Shape:\", df_custom.shape)\n",
    "print(\"\\nCustom Dataset - First 5 rows:\")\n",
    "print(df_custom.head())\n",
    "\n",
    "df_tips = sns.load_dataset('tips')\n",
    "df_flights = sns.load_dataset('flights')\n",
    "df_titanic = sns.load_dataset('titanic')\n",
    "\n",
    "print(f\"\\nTips Dataset Shape: {df_tips.shape}\")\n",
    "print(f\"Flights Dataset Shape: {df_flights.shape}\")\n",
    "print(f\"Titanic Dataset Shape: {df_titanic.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8df63ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   customer_id          20 non-null     int64  \n",
      " 1   age                  18 non-null     float64\n",
      " 2   income               18 non-null     float64\n",
      " 3   education_level      18 non-null     object \n",
      " 4   purchase_amount      19 non-null     float64\n",
      " 5   category             20 non-null     object \n",
      " 6   satisfaction_rating  17 non-null     float64\n",
      " 7   gender               20 non-null     object \n",
      " 8   total_purchases      20 non-null     int64  \n",
      "dtypes: float64(4), int64(2), object(3)\n",
      "memory usage: 1.5+ KB\n",
      "None\n",
      "\n",
      "Missing Values in Custom Dataset:\n",
      "customer_id            0\n",
      "age                    2\n",
      "income                 2\n",
      "education_level        2\n",
      "purchase_amount        1\n",
      "category               0\n",
      "satisfaction_rating    3\n",
      "gender                 0\n",
      "total_purchases        0\n",
      "dtype: int64\n",
      "\n",
      "Titanic Dataset Missing Values:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "\n",
      "Basic Statistics - Custom Dataset:\n",
      "       customer_id        age         income  purchase_amount  \\\n",
      "count     20.00000  18.000000      18.000000        19.000000   \n",
      "mean      10.50000  36.111111   68277.777778       226.376316   \n",
      "std        5.91608   9.946261   27239.257042       150.830825   \n",
      "min        1.00000  22.000000   28000.000000        45.300000   \n",
      "25%        5.75000  27.500000   46750.000000       111.100000   \n",
      "50%       10.50000  35.000000   65000.000000       178.600000   \n",
      "75%       15.25000  43.500000   83250.000000       322.050000   \n",
      "max       20.00000  55.000000  120000.000000       567.900000   \n",
      "\n",
      "       satisfaction_rating  total_purchases  \n",
      "count            17.000000        20.000000  \n",
      "mean              4.111765        21.700000  \n",
      "std               0.613272        13.183323  \n",
      "min               2.800000         3.000000  \n",
      "25%               3.800000        10.500000  \n",
      "50%               4.200000        21.500000  \n",
      "75%               4.600000        31.500000  \n",
      "max               4.900000        48.000000  \n"
     ]
    }
   ],
   "source": [
    "numerical_cols = ['age', 'income', 'purchase_amount', 'satisfaction_rating', 'total_purchases']\n",
    "categorical_cols = ['education_level', 'category', 'gender']\n",
    "\n",
    "print(\"\\nCustom Dataset Info:\")\n",
    "print(df_custom.info())\n",
    "print(\"\\nMissing Values in Custom Dataset:\")\n",
    "print(df_custom.isnull().sum())\n",
    "\n",
    "print(\"\\nTitanic Dataset Missing Values:\")\n",
    "print(df_titanic.isnull().sum())\n",
    "\n",
    "print(\"\\nBasic Statistics - Custom Dataset:\")\n",
    "print(df_custom.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3900edf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After mean imputation - missing values:\n",
      "customer_id            0\n",
      "age                    0\n",
      "income                 0\n",
      "education_level        2\n",
      "purchase_amount        0\n",
      "category               0\n",
      "satisfaction_rating    0\n",
      "gender                 0\n",
      "total_purchases        0\n",
      "dtype: int64\n",
      "After mode imputation - missing values:\n",
      "customer_id            0\n",
      "age                    0\n",
      "income                 0\n",
      "education_level        0\n",
      "purchase_amount        0\n",
      "category               0\n",
      "satisfaction_rating    0\n",
      "gender                 0\n",
      "total_purchases        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Praveen SB Nair\\AppData\\Local\\Temp\\ipykernel_27600\\417307253.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_processed['education_level'].fillna(df_processed['education_level'].mode()[0], inplace=True)\n",
      "C:\\Users\\Praveen SB Nair\\AppData\\Local\\Temp\\ipykernel_27600\\417307253.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_processed['category'].fillna(df_processed['category'].mode()[0], inplace=True)\n",
      "C:\\Users\\Praveen SB Nair\\AppData\\Local\\Temp\\ipykernel_27600\\417307253.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_processed['gender'].fillna(df_processed['gender'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "df_processed = df_custom.copy()\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_processed[numerical_cols] = imputer.fit_transform(df_processed[numerical_cols])\n",
    "print(\"After mean imputation - missing values:\")\n",
    "print(df_processed.isnull().sum())\n",
    "df_processed['education_level'].fillna(df_processed['education_level'].mode()[0], inplace=True)\n",
    "df_processed['category'].fillna(df_processed['category'].mode()[0], inplace=True)\n",
    "df_processed['gender'].fillna(df_processed['gender'].mode()[0], inplace=True)\n",
    "print(\"After mode imputation - missing values:\")\n",
    "print(df_processed.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87eb0a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic age missing values after KNN imputation: 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "df_titanic_processed = df_titanic.copy()\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_titanic_processed[['age']] = imputer.fit_transform(df_titanic_processed[['age']])\n",
    "print(\"Titanic age missing values after KNN imputation:\", df_titanic_processed['age'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c756635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Forward Fill - missing values:\n",
      "customer_id            0\n",
      "age                    2\n",
      "income                 2\n",
      "education_level        2\n",
      "purchase_amount        1\n",
      "category               0\n",
      "satisfaction_rating    3\n",
      "gender                 0\n",
      "total_purchases        0\n",
      "dtype: int64\n",
      "After Forward Fill - missing values:\n",
      "customer_id            0\n",
      "age                    0\n",
      "income                 0\n",
      "education_level        0\n",
      "purchase_amount        0\n",
      "category               0\n",
      "satisfaction_rating    0\n",
      "gender                 0\n",
      "total_purchases        0\n",
      "dtype: int64\n",
      "After Backward Fill - missing values:\n",
      "customer_id            0\n",
      "age                    0\n",
      "income                 0\n",
      "education_level        0\n",
      "purchase_amount        0\n",
      "category               0\n",
      "satisfaction_rating    0\n",
      "gender                 0\n",
      "total_purchases        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Praveen SB Nair\\AppData\\Local\\Temp\\ipykernel_27600\\1762504515.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sample_data.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\Praveen SB Nair\\AppData\\Local\\Temp\\ipykernel_27600\\1762504515.py:7: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sample_data.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "sample_data = df_custom.copy()\n",
    "print(\"Before Forward Fill - missing values:\")\n",
    "print(sample_data.isnull().sum())\n",
    "sample_data.fillna(method='ffill', inplace=True)\n",
    "print(\"After Forward Fill - missing values:\")\n",
    "print(sample_data.isnull().sum())\n",
    "sample_data.fillna(method='bfill', inplace=True)\n",
    "print(\"After Backward Fill - missing values:\")\n",
    "print(sample_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0036cd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (20, 9)\n",
      "After dropping rows with missing values: (11, 9)\n",
      "After dropping columns with missing values: (20, 4)\n"
     ]
    }
   ],
   "source": [
    "df_dropped_rows = df_custom.dropna(inplace=False)\n",
    "print(f\"Original shape: {df_custom.shape}\")\n",
    "print(f\"After dropping rows with missing values: {df_dropped_rows.shape}\")\n",
    "\n",
    "df_dropped_cols = df_custom.dropna(axis=1, inplace=False)\n",
    "print(f\"After dropping columns with missing values: {df_dropped_cols.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad518deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original statistics:\n",
      "             age         income  purchase_amount  satisfaction_rating  \\\n",
      "count  20.000000      20.000000        20.000000            20.000000   \n",
      "mean   36.111111   68277.777778       226.376316             4.111765   \n",
      "std     9.408221   25765.757684       146.807945             0.562777   \n",
      "min    22.000000   28000.000000        45.300000             2.800000   \n",
      "25%    28.500000   50250.000000       117.275000             3.875000   \n",
      "50%    35.555556   67638.888889       190.175000             4.111765   \n",
      "75%    42.500000   79750.000000       310.475000             4.525000   \n",
      "max    55.000000  120000.000000       567.900000             4.900000   \n",
      "\n",
      "       total_purchases  \n",
      "count        20.000000  \n",
      "mean         21.700000  \n",
      "std          13.183323  \n",
      "min           3.000000  \n",
      "25%          10.500000  \n",
      "50%          21.500000  \n",
      "75%          31.500000  \n",
      "max          48.000000  \n",
      "\n",
      "After Min-Max Scaling:\n",
      "             age     income  purchase_amount  satisfaction_rating  \\\n",
      "count  20.000000  20.000000        20.000000            20.000000   \n",
      "mean    0.427609   0.437802         0.346491             0.624650   \n",
      "std     0.285098   0.280063         0.280918             0.267989   \n",
      "min     0.000000   0.000000         0.000000             0.000000   \n",
      "25%     0.196970   0.241848         0.137725             0.511905   \n",
      "50%     0.410774   0.430857         0.277220             0.624650   \n",
      "75%     0.621212   0.562500         0.507415             0.821429   \n",
      "max     1.000000   1.000000         1.000000             1.000000   \n",
      "\n",
      "       total_purchases  \n",
      "count        20.000000  \n",
      "mean          0.415556  \n",
      "std           0.292963  \n",
      "min           0.000000  \n",
      "25%           0.166667  \n",
      "50%           0.411111  \n",
      "75%           0.633333  \n",
      "max           1.000000  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = df_processed.copy()\n",
    "\n",
    "df_scaled[numerical_cols] = scaler.fit_transform(df_processed[numerical_cols])\n",
    "\n",
    "print(\"Original statistics:\")\n",
    "print(df_processed[numerical_cols].describe())\n",
    "print(\"\\nAfter Min-Max Scaling:\")\n",
    "print(df_scaled[numerical_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "962c7663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Standard Scaling:\n",
      "                age        income  purchase_amount  satisfaction_rating  \\\n",
      "count  2.000000e+01  2.000000e+01     2.000000e+01         2.000000e+01   \n",
      "mean   4.496403e-16 -1.096345e-16     1.562986e-16         8.104628e-16   \n",
      "std    1.025978e+00  1.025978e+00     1.025978e+00         1.025978e+00   \n",
      "min   -1.538834e+00 -1.603839e+00    -1.265465e+00        -2.391430e+00   \n",
      "25%   -8.300013e-01 -7.178562e-01    -7.624627e-01        -4.316369e-01   \n",
      "50%   -6.058403e-02 -2.544021e-02    -2.529956e-01         1.619205e-15   \n",
      "75%    6.967164e-01  4.568176e-01     5.877300e-01         7.533539e-01   \n",
      "max    2.059857e+00  2.059551e+00     2.386764e+00         1.437002e+00   \n",
      "\n",
      "       total_purchases  \n",
      "count     2.000000e+01  \n",
      "mean      1.665335e-17  \n",
      "std       1.025978e+00  \n",
      "min      -1.455308e+00  \n",
      "25%      -8.716283e-01  \n",
      "50%      -1.556479e-02  \n",
      "75%       7.626748e-01  \n",
      "max       2.046770e+00  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_standard = df_processed.copy()\n",
    "df_standard[numerical_cols] = scaler.fit_transform(df_processed[numerical_cols])\n",
    "\n",
    "print(\"After Standard Scaling:\")\n",
    "print(df_standard[numerical_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a43f9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After L2 Normalization:\n",
      "             age     income  purchase_amount  satisfaction_rating  \\\n",
      "count  20.000000  20.000000        20.000000            20.000000   \n",
      "mean    0.000560   0.999994         0.003104             0.000068   \n",
      "std     0.000109   0.000004         0.001164             0.000025   \n",
      "min     0.000400   0.999982         0.000993             0.000041   \n",
      "25%     0.000469   0.999993         0.002257             0.000050   \n",
      "50%     0.000552   0.999995         0.003231             0.000061   \n",
      "75%     0.000637   0.999997         0.003679             0.000076   \n",
      "max     0.000786   0.999999         0.006010             0.000125   \n",
      "\n",
      "       total_purchases  \n",
      "count        20.000000  \n",
      "mean          0.000296  \n",
      "std           0.000111  \n",
      "min           0.000073  \n",
      "25%           0.000242  \n",
      "50%           0.000322  \n",
      "75%           0.000338  \n",
      "max           0.000539  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer = Normalizer(norm='l2')\n",
    "df_normalized = df_processed.copy()\n",
    "df_normalized[numerical_cols] = normalizer.fit_transform(df_processed[numerical_cols])\n",
    "\n",
    "print(\"After L2 Normalization:\")\n",
    "print(df_normalized[numerical_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c8275a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender Label Encoding:\n",
      "   gender  gender_encoded\n",
      "1  Female               0\n",
      "0    Male               1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_encoded = df_processed.copy()\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_encoded['gender_encoded'] = le.fit_transform(df_encoded['gender'])\n",
    "\n",
    "print(\"Gender Label Encoding:\")\n",
    "print(df_encoded[['gender', 'gender_encoded']].drop_duplicates().sort_values('gender'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05105164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded category columns:\n",
      "Index(['category_Books', 'category_Clothing', 'category_Electronics'], dtype='object')\n",
      "\n",
      "One-hot encoded data:\n",
      "   category_Books  category_Clothing  category_Electronics\n",
      "0           False              False                  True\n",
      "1           False               True                 False\n",
      "2            True              False                 False\n",
      "3           False              False                  True\n",
      "4           False               True                 False\n"
     ]
    }
   ],
   "source": [
    "df_onehot = pd.get_dummies(df_encoded['category'], prefix='category')\n",
    "print(\"One-hot encoded category columns:\")\n",
    "print(df_onehot.columns)\n",
    "print(\"\\nOne-hot encoded data:\")\n",
    "print(df_onehot.head())\n",
    "\n",
    "df_encoded = pd.concat([df_encoded, df_onehot], axis=1)\n",
    "df_encoded.drop('category', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3152681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education Level Ordinal Encoding:\n",
      "  education_level  encoded_value\n",
      "0     High School              0\n",
      "1        Bachelor              1\n",
      "2          Master              2\n",
      "3             PhD              3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "encoder = OrdinalEncoder(categories=[['High School', 'Bachelor', 'Master', 'PhD']])\n",
    "df_encoded['education_level_encoded'] = encoder.fit_transform(df_encoded[['education_level']])\n",
    "\n",
    "print(\"Education Level Ordinal Encoding:\")\n",
    "education_mapping = pd.DataFrame({\n",
    "    'education_level': ['High School', 'Bachelor', 'Master', 'PhD'],\n",
    "    'encoded_value': [0, 1, 2, 3]\n",
    "})\n",
    "print(education_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78855217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age equal-width binning:\n",
      "age_bins_equal\n",
      "Adult          7\n",
      "Young          6\n",
      "Middle-aged    4\n",
      "Senior         3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_binned = df_processed.copy()\n",
    "\n",
    "df_binned['age_bins_equal'] = pd.cut(df_binned['age'], bins=4, labels=['Young', 'Adult', 'Middle-aged', 'Senior'])\n",
    "print(\"Age equal-width binning:\")\n",
    "print(df_binned['age_bins_equal'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84af95bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age equal-frequency binning:\n",
      "age_bins_quantile\n",
      "Q1    5\n",
      "Q2    5\n",
      "Q3    5\n",
      "Q4    5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_binned['age_bins_quantile'] = pd.qcut(df_binned['age'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "print(\"Age equal-frequency binning:\")\n",
    "print(df_binned['age_bins_quantile'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf9b0059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom age binning:\n",
      "age_bins_custom\n",
      "Young Adult    12\n",
      "Youth           6\n",
      "Middle Age      2\n",
      "Senior          0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "custom_bins = [0, 30, 50, 70, 100]\n",
    "custom_labels = ['Youth', 'Young Adult', 'Middle Age', 'Senior']\n",
    "df_binned['age_bins_custom'] = pd.cut(df_binned['age'], bins=custom_bins, labels=custom_labels)\n",
    "\n",
    "print(\"Custom age binning:\")\n",
    "print(df_binned['age_bins_custom'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbd98164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips dataset missing values: 0\n",
      "Tips dataset after preprocessing shape: (244, 13)\n",
      "Tips dataset columns: ['total_bill', 'tip', 'size', 'sex_Male', 'sex_Female', 'smoker_Yes', 'smoker_No', 'day_Thur', 'day_Fri', 'day_Sat', 'day_Sun', 'time_Lunch', 'time_Dinner']\n"
     ]
    }
   ],
   "source": [
    "df_tips_processed = df_tips.copy()\n",
    "print(\"Tips dataset missing values:\", df_tips_processed.isnull().sum().sum())\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_tips_processed[['total_bill', 'tip', 'size']] = scaler.fit_transform(df_tips_processed[['total_bill', 'tip', 'size']])\n",
    "\n",
    "df_tips_processed = pd.get_dummies(df_tips_processed, columns=['sex', 'smoker', 'day', 'time'])\n",
    "\n",
    "print(\"Tips dataset after preprocessing shape:\", df_tips_processed.shape)\n",
    "print(\"Tips dataset columns:\", list(df_tips_processed.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9256f4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic dataset after preprocessing shape: (891, 22)\n",
      "Missing values after preprocessing: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Praveen SB Nair\\AppData\\Local\\Temp\\ipykernel_27600\\3876580967.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_titanic_final['embarked'].fillna(df_titanic_final['embarked'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_titanic_final = df_titanic.copy()\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_titanic_final[['age']] = imputer.fit_transform(df_titanic_final[['age']])\n",
    "\n",
    "df_titanic_final['embarked'].fillna(df_titanic_final['embarked'].mode()[0], inplace=True)\n",
    "\n",
    "df_titanic_final.drop('deck', axis=1, inplace=True)\n",
    "\n",
    "titanic_numerical_cols = ['age', 'fare']\n",
    "scaler = StandardScaler()\n",
    "df_titanic_final[titanic_numerical_cols] = scaler.fit_transform(df_titanic_final[titanic_numerical_cols])\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_titanic_final['sex_encoded'] = le.fit_transform(df_titanic_final['sex'])\n",
    "df_titanic_final['alive_encoded'] = le.fit_transform(df_titanic_final['alive'])\n",
    "\n",
    "df_titanic_final = pd.get_dummies(df_titanic_final, columns=['embarked', 'class', 'who'])\n",
    "\n",
    "print(\"Titanic dataset after preprocessing shape:\", df_titanic_final.shape)\n",
    "print(\"Missing values after preprocessing:\", df_titanic_final.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fef50fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flights dataset after preprocessing shape: (144, 15)\n"
     ]
    }
   ],
   "source": [
    "df_flights_processed = df_flights.copy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_flights_processed[['passengers']] = scaler.fit_transform(df_flights_processed[['passengers']])\n",
    "\n",
    "df_flights_processed['decade'] = pd.cut(df_flights_processed['year'], \n",
    "                                      bins=[1940, 1950, 1960, 1970], \n",
    "                                      labels=['1940s', '1950s', '1960s'])\n",
    "\n",
    "df_flights_processed = pd.get_dummies(df_flights_processed, columns=['month'])\n",
    "\n",
    "print(\"Flights dataset after preprocessing shape:\", df_flights_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28ea3f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Dataset: (20, 13)\n",
      "Tips Dataset: (244, 13)\n",
      "Titanic Dataset: (891, 22)\n",
      "Flights Dataset: (144, 15)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Custom Dataset: {df_encoded.shape}\")\n",
    "print(f\"Tips Dataset: {df_tips_processed.shape}\")\n",
    "print(f\"Titanic Dataset: {df_titanic_final.shape}\")\n",
    "print(f\"Flights Dataset: {df_flights_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f659ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
